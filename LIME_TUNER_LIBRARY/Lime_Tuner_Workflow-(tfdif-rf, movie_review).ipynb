{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "\n",
    "import scipy\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tuner_library\n",
    "import utilities as util\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRmse1(actual_preds, target_preds):\n",
    "    rmse_val = 0\n",
    "    for x in range(len(actual_preds)):\n",
    "        rmse_val += (float(target_preds[x])- actual_preds[x])*(float(target_preds[x]) - actual_preds[x])\n",
    "    #print(rmse_val)\n",
    "    rmse_val = float(rmse_val)/len(target_preds)\n",
    "    return rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "#ask user to input the name of classes and store it in classNames as a json\n",
    "class_names = ['negative', 'positive']\n",
    "class_names = json.dumps(class_names)\n",
    "\n",
    "#converting json to array object which will be used by the code further\n",
    "class_names = json.loads(class_names)\n",
    "print(class_names)\n",
    "\n",
    "#get the text from the user in the string form(not json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(df[0], df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(train_features)\n",
    "test_vectors = vectorizer.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2751445086705202"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rf.predict(test_vectors)\n",
    "sklearn.metrics.f1_score(test_labels, pred, average='binary')\n",
    "getRmse1(test_labels.tolist(), pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(c, open(\"model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 200\n",
    "text = df[0][i]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tuner_library import tuner\n",
    "tl = tuner(text,'model.pkl', class_names)\n",
    "result = util.JsonToArray(tl.get_Prediction()) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask user to input the value of sigma and store it in sigma as a json\n",
    "sigma = 25\n",
    "sigma = json.dumps(sigma)\n",
    "\n",
    "#converting json to array object which will be used by the code further\n",
    "sigma = json.loads(sigma)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the explanation for a particular sigma (all the explanation fields are filled)\n",
    "exp = tl.get_Explanation(sigma)\n",
    "print(exp.rf_score)\n",
    "exp.save_to_file('explanation_25.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.39062499968\n",
    "tl.sigmas = k*2**np.arange(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in tl.sigmas:\n",
    "    exp = tl.get_Explanation(sigma)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting entropy v/s sigma curve\n",
    "sigmas, entropies = tl.get_Sigma_Entropy()\n",
    "#get the rmse values(all the explanation models) for all the sigmas \n",
    "sigmas,constant_rmse, linear_rmse, decisionTree_rmse, randomForest_rmse = tl.get_RMSEs_And_Sigmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the sigma v/s rmses \n",
    "axes=plt.gca()\n",
    "\n",
    "plt.xscale('log', basex = 2)\n",
    "plt.xlabel(\"sigma\")\n",
    "plt.ylabel(\"rmse\");\n",
    "\n",
    "plt.plot(sigmas, randomForest_rmse,'-o',label = 'random_forest')\n",
    "plt.plot(sigmas, decisionTree_rmse,'-o',label = 'decision_tree')\n",
    "plt.plot(sigmas, linear_rmse,'-o', label = 'linear_model')\n",
    "# plt.plot(width, constant_rmse,'-o',label = 'constant_model')\n",
    "# plt.suptitle('Example id = ' + str(idx))\n",
    "\n",
    "legend = plt.legend(loc='upper left', shadow=True)\n",
    "\n",
    "legend.get_frame()\n",
    "\n",
    "#plot the sigma v/s rmses \n",
    "# axes=plt.gca()\n",
    "\n",
    "# plt.xscale('log', basex = 2)\n",
    "# plt.xlabel(\"sigma\")\n",
    "# plt.ylabel(\"rmse\");\n",
    "\n",
    "# plt.plot(sigmas[0:4], randomForest_rmse[0:4],'-o',label = 'random_forest')\n",
    "# plt.plot(sigmas[0:4], decisionTree_rmse[0:4],'-o',label = 'decision_tree')\n",
    "# plt.plot(sigmas[0:4], linear_rmse[0:4],'-o', label = 'linear_model')\n",
    "# plt.plot(sigmas[0:4], constant_rmse[0:4],'-o',label = 'constant_model')\n",
    "# # plt.suptitle('Example id = ' + str(idx))\n",
    "\n",
    "# legend = plt.legend(loc='upper left', shadow=True)\n",
    "\n",
    "# legend.get_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting weight distribution of neighbourhood points for a particular sigma\n",
    "weights, predictions = tl.get_Weight_Distribution_Plot_Per_Sigma(25)\n",
    "\n",
    "#plot the weight distribution of neighbour points for a particular sigma\n",
    "axes=plt.gca()\n",
    "plt.ylabel(\"weights\")\n",
    "plt.xlabel(\"prediction\");\n",
    "plt.ylim(-0.5, 1.5)\n",
    "major_ticks = np.arange(-0.5, 1.5, 0.5)\n",
    "axes.set_yticks(major_ticks) \n",
    "plt.xlim(0,1)\n",
    "print(sigma)\n",
    "plt.plot(predictions, weights,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tl.getRange_Constant_Model())\n",
    "print(tl.getRange_Linear_Model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_rmse)\n",
    "print(constant_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
